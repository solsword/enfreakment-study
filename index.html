<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>README</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="js/examples.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="analyzing-ethnic-enfreakment">Analyzing Ethnic Enfreakment</h1>
<p>This repository contains code and data from an online study that sought to measure some of the contours of ethnic enfreakment in fighting games (Street Fighter V and Tekken 7 specifically).</p>
<p>The <code>turk/</code> folder contains the HTML templates and other data required to construct the Amazon Mechanical Turk Human Intelligence Tasks (HITs) that we used to carry out the study. There is code there which was used to create randomized HITs and put together templates, etc. The <code>Makefile</code> in that directory, although not well-documented, should give a sense of how things fit together; it relies on the <code>clingo</code> constraint solving library to create counterbalanced character groupings, as well as <code>python</code> for some of the scripts.</p>
<p>If you want to see an example of a fully constructed HIT, the <a href="turk/template-local.html"><code>turk/tempalte-local.html</code></a> file shows what a single HIT template looks like when filled out; if you are viewing it locally you should run <code>make template-local.html</code> in the <code>turk/</code> folder first otherwise the images will not show up.</p>
<p>The <code>data/</code> folder contains both anonymized survey response data (in the file <a href="data/efr.tsv"><code>efr.tsv</code></a>) as well as code for analyzing it based on our hypotheses. Again, the <code>Makefile</code> shows how things fit together; note that there are some rules there for processing the raw data, but based on our study protocols this raw data which contains AMT user IDs cannot be made public.</p>
<p>The analysis code uses the <code>scipy</code> and <code>krippendorf</code> Python packages, and should work with Python versions roughly 3.5-5.8 at least. It uses fairly large bootstrap samples to do statistics, and can take dozens of minutes or more to finish, although it does print progress messages (try <code>tail -f report.txt</code> while <code>make report.txt</code> is running).</p>
<p>The <code>Makefile</code> scripts assume a POSIX environment and probably a few GNU utilities on top of that, so they’re easiest to run in a Mac or Linux environment, but you could run some of the data processing steps manually if you wanted to, and if you’re designing a similar study or if you just want to run your own analysis of the data, you can likely simplify things enormously.</p>
</body>
</html>
